# ğŸ›ï¸ Amazon Smart Web Scraper API

This project is a dynamic web scraper that retrieves product data from Amazon.com based on a search query and serves it through a FastAPI-based RESTful API. It includes JSON-formatted logging and retry mechanisms for reliability.

---

## ğŸ“Œ Features

- ğŸ” Scrape Amazon products by keyword with pagination support
- ğŸ“¦ Product details include: title, price, rating, review count, image, and product link
- âœ… Product validity check for data completeness
- ğŸ” Built-in retry strategy for unstable connections
- ğŸ“„ Pagination support to scrape and return results from multiple pages
- ğŸ“„ Structured JSON logging (file + console)
- ğŸ’¾ SQLite database to store results  
- ğŸ§® Filter and sort products by price, rating, and review count using efficient DB queries  
- â¬‡ï¸ One-click export and download of filtered results as CSV or JSON  
- âš™ï¸ Development & production environment modes

---

## ğŸ§± Technologies Used

- **FastAPI** â€” Modern Python web framework
- **BeautifulSoup4** â€” HTML parsing
- **Requests + Retry** â€” HTTP connection handling
- **Pydantic** â€” Data modeling
- **SQLite + SQLModel** â€” Lightweight database and ORM for data persistence and filtering
- **Logging** â€” Structured JSON log system
- **RotatingFileHandler** â€” File-based rotating logging system

---

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/ErcanKurtoglu/product_search.git
cd product_search
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # For Windows: venv\Scripts\activate
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```
## âš™ï¸ Usage

### To Run all project via Streamlit app

```bash
python run.py
```
The application will be opened via web browser or can be opened manually `localhost:5000`

### Run the API only

```bash
uvicorn app.main:app --reload
```

### Endpoint

`GET /search?query=your_search_term`

#### Example:
```http
GET http://127.0.0.1:8000/search?query=laptop
```

#### Response

```json
[
  {
    "title": "Laptop Model XYZ",
    "price": 849.99,
    "rating": 4.5,
    "review_count": 187,
    "product_url": "https://www.amazon.com/dp/XYZ",
    "image_url": "https://m.media-amazon.com/images/I/XYZ.jpg",
    "valid": true
  },
  ...
]
```

## ğŸ§ª Testing

### Manual Test Script:

```python
from app.scraper import scraping_for_test

product, status = scraping_for_test("laptop")
print(product)
```

## ğŸ“ Project Structure

```graphql
product_search/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py              # Streamlit app
â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”œâ”€â”€ scraper.py          # Scraper logic
â”‚   â”œâ”€â”€ models.py           # Pydantic models
â”‚   â”œâ”€â”€ db_models.py        # SQLModel ORM models
â”‚   â”œâ”€â”€ databese.py         # DB setup
â”‚   â”œâ”€â”€ search_service.py   # Search & filtering services with DB queries
â”‚   â”œâ”€â”€ exceptions.py       # Defined exception classes
â”‚   â””â”€â”€ logger.py           # JSON logger config
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ app.db              # All product db 
â”‚   â”œâ”€â”€ temp_app.db         # Live search products filtered db 
â”‚   â”œâ”€â”€ temp_hist.db        # Historical search products filtered db 
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py    # App test 
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log        # Rotating JSON log file (auto-generated)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ run.py             # Project run
â””â”€â”€ README.md
```

.env file:
```.env
# .env
APP_ENV=production
```

## ğŸ“Š Logging System

* **File:** `logs/app.log`

* **Format:** JSON

* **Fields:**

  * `timestamp`, `level`, `logger`, `message`, `file`, `line`, `function`

#### Example log entry:

```json
{
  "timestamp": "2025-05-30T14:45:01.123456Z",
  "level": "INFO",
  "logger": "api.scraper",
  "message": "Scraping started for query: 'laptop'",
  "file": "/app/api/scraper.py",
  "line": 32,
  "function": "scrape_amazon_products"
}
```


## âš ï¸ Warnings

* Amazon's HTML structure changes frequently. The scraper should be kept up-to-date.

* Amazon employs bot protection mechanisms. Excessive use may result in IP bans.

* This project is for educational and personal use only. Commercial use may lead to legal issues.


## ğŸ“¬ Developer Note

This project demonstrates a professional approach to dynamic data scraping, API development, and structured logging. Optional enhancements include Redis, database integration, and cron-based automation.


## ğŸ“ License

This project is licensed under the **MIT License**.  
See the [LICENSE](./LICENSE) file for details.